{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPGNN: Molecule Prediction with Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.0.1\n",
      "Cuda available: False\n",
      "Torch geometric version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import numpy as np \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        root = Where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processed_dir (processed data). \n",
    "        \"\"\"\n",
    "        self.test = test\n",
    "        self.filename = filename\n",
    "        super(MoleculeDataset, self).__init__(root, transform, pre_transform)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
    "            (The download func. is not implemented here)  \n",
    "        \"\"\"\n",
    "        return self.filename\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
    "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
    "\n",
    "        if self.test:\n",
    "            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
    "        else:\n",
    "            return [f'data_{i}.pt' for i in list(self.data.index)]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0])\n",
    "        for index, mol in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
    "            mol_obj = Chem.MolFromSmiles(mol[\"smiles\"])\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(mol_obj)\n",
    "            # Get edge features\n",
    "            edge_feats = self._get_edge_features(mol_obj)\n",
    "            # Get adjacency info\n",
    "            edge_index = self._get_adjacency_info(mol_obj)\n",
    "            # Get labels info\n",
    "            label = self._get_labels(mol[\"HIV_active\"])\n",
    "\n",
    "            # Create data object\n",
    "            data = Data(x=node_feats, \n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_feats,\n",
    "                        y=label,\n",
    "                        smiles=mol[\"smiles\"]\n",
    "                        ) \n",
    "            if self.test:\n",
    "                torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_test_{index}.pt'))\n",
    "            else:\n",
    "                torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_{index}.pt'))\n",
    "\n",
    "    def _get_node_features(self, mol):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of Nodes, Node Feature size]\n",
    "        \"\"\"\n",
    "        all_node_feats = []\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            node_feats = []\n",
    "            # Feature 1: Atomic number        \n",
    "            node_feats.append(atom.GetAtomicNum())\n",
    "            # Feature 2: Atom degree\n",
    "            node_feats.append(atom.GetDegree())\n",
    "            # Feature 3: Formal charge\n",
    "            node_feats.append(atom.GetFormalCharge())\n",
    "            # Feature 4: Hybridization\n",
    "            node_feats.append(atom.GetHybridization())\n",
    "            # Feature 5: Aromaticity\n",
    "            node_feats.append(atom.GetIsAromatic())\n",
    "            # Feature 6: Total Num Hs\n",
    "            node_feats.append(atom.GetTotalNumHs())\n",
    "            # Feature 7: Radical Electrons\n",
    "            node_feats.append(atom.GetNumRadicalElectrons())\n",
    "            # Feature 8: In Ring\n",
    "            node_feats.append(atom.IsInRing())\n",
    "            # Feature 9: Chirality\n",
    "            node_feats.append(atom.GetChiralTag())\n",
    "\n",
    "            # Append node features to matrix\n",
    "            all_node_feats.append(node_feats)\n",
    "\n",
    "        all_node_feats = np.asarray(all_node_feats)\n",
    "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_edge_features(self, mol):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of edges, Edge Feature size]\n",
    "        \"\"\"\n",
    "        all_edge_feats = []\n",
    "\n",
    "        for bond in mol.GetBonds():\n",
    "            edge_feats = []\n",
    "            # Feature 1: Bond type (as double)\n",
    "            edge_feats.append(bond.GetBondTypeAsDouble())\n",
    "            # Feature 2: Rings\n",
    "            edge_feats.append(bond.IsInRing())\n",
    "            # Append node features to matrix (twice, per direction)\n",
    "            all_edge_feats += [edge_feats, edge_feats]\n",
    "\n",
    "        all_edge_feats = np.asarray(all_edge_feats)\n",
    "        return torch.tensor(all_edge_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_adjacency_info(self, mol):\n",
    "        \"\"\"\n",
    "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
    "        but we want to be sure that the order of the indices\n",
    "        matches the order of the edge features\n",
    "        \"\"\"\n",
    "        edge_indices = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_indices += [[i, j], [j, i]]\n",
    "\n",
    "        edge_indices = torch.tensor(edge_indices)\n",
    "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
    "        return edge_indices\n",
    "\n",
    "    def _get_labels(self, label):\n",
    "        label = np.asarray([label])\n",
    "        return torch.tensor(label, dtype=torch.int64)\n",
    "\n",
    "    def len(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
    "            - Is not needed for PyG's InMemoryDataset\n",
    "        \"\"\"\n",
    "        if self.test:\n",
    "            data = torch.load(os.path.join(self.processed_dir, f'data_test_{idx}.pt'))\n",
    "        else:\n",
    "            data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))   \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MoleculeDataset(root=\"./data/HIV/\", filename=\"HIV_train_oversampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0].edge_index.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling \n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size, model_params):\n",
    "        super(GNN, self).__init__()\n",
    "        embedding_size = model_params[\"model_embedding_size\"]\n",
    "        n_heads = model_params[\"model_attention_heads\"]\n",
    "        self.n_layers = model_params[\"model_layers\"]\n",
    "        dropout_rate = model_params[\"model_dropout_rate\"]\n",
    "        top_k_ratio = model_params[\"model_top_k_ratio\"]\n",
    "        self.top_k_every_n = model_params[\"model_top_k_every_n\"]\n",
    "        dense_neurons = model_params[\"model_dense_neurons\"]\n",
    "        edge_dim = model_params[\"model_edge_dim\"]\n",
    "\n",
    "        self.conv_layers = ModuleList([])\n",
    "        self.transf_layers = ModuleList([])\n",
    "        self.pooling_layers = ModuleList([])\n",
    "        self.bn_layers = ModuleList([])\n",
    "\n",
    "        # Transformation layer\n",
    "        self.conv1 = TransformerConv(feature_size, \n",
    "                                    embedding_size, \n",
    "                                    heads=n_heads, \n",
    "                                    dropout=dropout_rate,\n",
    "                                    edge_dim=edge_dim,\n",
    "                                    beta=True) \n",
    "\n",
    "        self.transf1 = Linear(embedding_size*n_heads, embedding_size)\n",
    "        self.bn1 = BatchNorm1d(embedding_size)\n",
    "\n",
    "        # Other layers\n",
    "        for i in range(self.n_layers):\n",
    "            self.conv_layers.append(TransformerConv(embedding_size, \n",
    "                                                    embedding_size, \n",
    "                                                    heads=n_heads, \n",
    "                                                    dropout=dropout_rate,\n",
    "                                                    edge_dim=edge_dim,\n",
    "                                                    beta=True))\n",
    "\n",
    "            self.transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n",
    "            self.bn_layers.append(BatchNorm1d(embedding_size))\n",
    "            if i % self.top_k_every_n == 0:\n",
    "                self.pooling_layers.append(TopKPooling(embedding_size, ratio=top_k_ratio))\n",
    "            \n",
    "\n",
    "        # Linear layers\n",
    "        self.linear1 = Linear(embedding_size*2, dense_neurons)\n",
    "        self.linear2 = Linear(dense_neurons, int(dense_neurons/2))  \n",
    "        self.linear3 = Linear(int(dense_neurons/2), 1)  \n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "        # Initial transformation\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = torch.relu(self.transf1(x))\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # Holds the intermediate graph representations\n",
    "        global_representation = []\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.conv_layers[i](x, edge_index, edge_attr)\n",
    "            x = torch.relu(self.transf_layers[i](x))\n",
    "            x = self.bn_layers[i](x)\n",
    "            # Always aggregate last layer\n",
    "            if i % self.top_k_every_n == 0 or i == self.n_layers:\n",
    "                x , edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[int(i/self.top_k_every_n)](\n",
    "                    x, edge_index, edge_attr, batch_index\n",
    "                    )\n",
    "                # Add current representation\n",
    "                global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n",
    "    \n",
    "        x = sum(global_representation)\n",
    "\n",
    "        # Output block\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv.TransformerConv: https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.TransformerConv.html#torch_geometric.nn.conv.TransformerConv \n",
    "To check other layers: https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html\n",
    "\n",
    "Transformer is a transduction model. These models are a type of neural network that processes an input sequence and generates an output sequence. They are used in machine learning and are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism.\n",
    "\n",
    "Transformer has an encoder-decoder structureth, where encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence of continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output sequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive, consuming the previously generated symbols as additional input when generating the next.\n",
    "\n",
    "heads: Number of multi-head-attentions. Multi-head attention is used to allow the model to jointly attend to information from different representation sub-spaces at different viewpoints. In practice, given the same set of queries, keys, and values (for example, query: node1, key: node2, value: edge value between node1 and node2 sets could be node features) we may want our model to combine knowledge from different behaviors of the same attention mechanism, such as capturing dependencies of various ranges (e.g., dependencies between nodes with different distances, like neighbor nodes or nodes connected with a 3-hop path) within a sequence. Thus, it may be beneficial to allow our attention mechanism to jointly use different representation subspaces of queries, keys, and values. To this end, instead of performing a single attention pooling, queries, keys, and values can be transformed with h independently learned linear projections. Then these h projected queries, keys, and values are fed into attention pooling in parallel. In the end, h attention pooling outputs are concatenated and transformed with another learned linear projection to produce the final output. This design is called multi-head attention, where each of the h attention pooling outputs is a head. For more details see the following links:\n",
    "- https://d2l.djl.ai/chapter_attention-mechanisms/multihead-attention.html\n",
    "- Attention is all you need: https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
    "- GNN Project #3.2 - Graph Transformer\n",
    "\n",
    "dropout: Dropout probability of the normalized attention coefficients which exposes each node to a stochastically sampled neighborhood during training. (default: 0)\n",
    "\n",
    "beta: It enables some weighted aggregation.\n",
    "\n",
    "TopKPooling: Keeping K nodes of the input graph for another round of message passing and aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"sgd_momentum\": 0.8,\n",
    "    \"scheduler_gamma\": 0.8,\n",
    "    \"pos_weight\": 1.3,\n",
    "    \"model_embedding_size\": 64,\n",
    "    \"model_attention_heads\": 3,\n",
    "    \"model_layers\": 4,\n",
    "    \"model_dropout_rate\": 0.2,\n",
    "    \"model_top_k_ratio\": 0.5,\n",
    "    \"model_top_k_every_n\": 10,\n",
    "    \"model_dense_neurons\": 256\n",
    "}\n",
    "\n",
    "model_params = {k: v for k, v in params.items() if k.startswith(\"model_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataset = MoleculeDataset(\n",
    "    root=\"data/HIV/\", filename=\"HIV_train_oversampled.csv\")\n",
    "test_dataset = MoleculeDataset(\n",
    "    root=\"data/HIV/\", filename=\"HIV_test.csv\", test=True)\n",
    "model_params[\"model_edge_dim\"] = train_dataset[0].edge_attr.shape[1]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "\n",
    "model = GNN(\n",
    "    feature_size=train_dataset[0].x.shape[1], model_params=model_params)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "weight = torch.tensor([params[\"pos_weight\"]], dtype=torch.float32).to(device)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "optimizer = torch.optim.SGD(model.parameters(\n",
    "), lr=params[\"learning_rate\"], momentum=params[\"sgd_momentum\"], weight_decay=params[\"weight_decay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 2], y=[1], smiles='N#CCCN(CCC#N)c1ccc(C=C2SC(=S)NC2=O)cc1')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
      "DataBatch(x=[4271, 9], edge_index=[2, 9126], edge_attr=[9126, 2], y=[128], smiles=[128], batch=[4271], ptr=[129])\n"
     ]
    }
   ],
   "source": [
    "for _, batch in enumerate(train_loader):\n",
    "    print(batch.batch)\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "      all_preds = []\n",
    "      all_labels = []\n",
    "      running_loss = 0.0\n",
    "      step = 0\n",
    "      for _, batch in enumerate(train_loader):\n",
    "            batch.to(device)\n",
    "            model.train()  \n",
    "            optimizer.zero_grad() \n",
    "            \n",
    "            pred = model(batch.x.float(), \n",
    "                                    batch.edge_attr.float(),\n",
    "                                    batch.edge_index, \n",
    "                                    batch.batch) \n",
    "\n",
    "            loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            # Update tracking\n",
    "            running_loss += loss.item()\n",
    "            step += 1\n",
    "            all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "            all_labels.append(batch.y.cpu().detach().numpy())\n",
    "      all_preds = np.concatenate(all_preds).ravel()\n",
    "      all_labels = np.concatenate(all_labels).ravel()\n",
    "      return running_loss/step   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.7188\n",
      "Epoch: 001, Loss: 0.7092\n",
      "Epoch: 002, Loss: 0.7001\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(0, 3): #range(0, 1001)\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
